#[cfg(feature = "builtin-llm")]
use pocketflow_rs::node::builtin::{ApiConfig, ApiRequestNode};
use pocketflow_rs::{Action, ExecutionContext, InMemoryStorage, SharedStore, node::NodeBackend};
use serde_json::json;
use std::io::{self, Write};
use std::time::Duration;
use tokio;

/// ç®€å•çš„æµå¼èŠå¤©æœºå™¨äºº
/// æ¼”ç¤º PocketFlow-rs æµå¼APIåŠŸèƒ½çš„åŸºæœ¬ç”¨æ³•
#[tokio::main]
async fn main() -> Result<(), Box<dyn std::error::Error>> {
    #[cfg(not(feature = "builtin-llm"))]
    {
        println!("âŒ æ­¤ç¤ºä¾‹éœ€è¦å¯ç”¨ 'builtin-llm' feature");
        println!("è¯·ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤è¿è¡Œï¼š");
        println!("cargo run --example simple_chatbot --features builtin-llm");
        return Ok(());
    }

    #[cfg(feature = "builtin-llm")]
    run_chatbot().await
}

#[cfg(feature = "builtin-llm")]
async fn run_chatbot() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ¤– ç®€å•æµå¼èŠå¤©æœºå™¨äºº");
    println!("===================");
    println!("æç¤º: éœ€è¦è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡");
    println!("è¾“å…¥ 'bye' é€€å‡ºèŠå¤©\n");

    // æ£€æŸ¥APIå¯†é’¥
    let api_key = std::env::var("OPENAI_API_KEY").unwrap_or_else(|_| {
        println!("âš ï¸  æœªæ‰¾åˆ° OPENAI_API_KEYï¼Œä½¿ç”¨æ¼”ç¤ºå¯†é’¥");
        "demo_key".to_string()
    });

    // åˆå§‹åŒ–å­˜å‚¨å’Œæ‰§è¡Œä¸Šä¸‹æ–‡
    let mut store: SharedStore<InMemoryStorage> = SharedStore::new();
    let execution_context = ExecutionContext::new(3, Duration::from_secs(30));

    // åˆ›å»ºæµå¼APIé…ç½®
    let streaming_config = ApiConfig {
        api_key: api_key.clone(),
        base_url: None,
        org_id: None,
        model: "gpt-3.5-turbo".to_string(),
        max_tokens: Some(500),
        temperature: Some(0.7),
        top_p: None,
        frequency_penalty: None,
        presence_penalty: None,
        timeout: Some(30),
        stream: true, // å¯ç”¨æµå¼
    };

    // åˆ›å»ºéæµå¼APIé…ç½®ç”¨äºå¯¹æ¯”
    let regular_config = ApiConfig {
        stream: false, // ç¦ç”¨æµå¼
        ..streaming_config.clone()
    };

    // åˆ›å»ºAPIèŠ‚ç‚¹
    let mut streaming_node = ApiRequestNode::new("input", "output", Action::simple("next"))
        .with_config(streaming_config)
        .with_system_message("ä½ æ˜¯ä¸€ä¸ªå‹å–„çš„AIåŠ©æ‰‹ï¼Œç”¨ä¸­æ–‡å›ç­”é—®é¢˜ã€‚");

    let mut regular_node = ApiRequestNode::new("input", "output", Action::simple("next"))
        .with_config(regular_config)
        .with_system_message("ä½ æ˜¯ä¸€ä¸ªå‹å–„çš„AIåŠ©æ‰‹ï¼Œç”¨ä¸­æ–‡å›ç­”é—®é¢˜ã€‚");

    // èŠå¤©å¾ªç¯
    let mut use_streaming = true;

    loop {
        // æ˜¾ç¤ºæç¤ºç¬¦
        let mode = if use_streaming { "æµå¼" } else { "å¸¸è§„" };
        print!("\n[{}] ä½ : ", mode);
        io::stdout().flush()?;

        // è¯»å–ç”¨æˆ·è¾“å…¥
        let mut input = String::new();
        io::stdin().read_line(&mut input)?;
        let user_input = input.trim();

        // å¤„ç†é€€å‡ºå‘½ä»¤
        if user_input == "bye" || user_input == "quit" {
            println!("ğŸ‘‹ å†è§ï¼");
            break;
        }

        // åˆ‡æ¢æ¨¡å¼å‘½ä»¤
        if user_input == "toggle" {
            use_streaming = !use_streaming;
            println!(
                "âœ… å·²åˆ‡æ¢åˆ°{}æ¨¡å¼",
                if use_streaming { "æµå¼" } else { "å¸¸è§„" }
            );
            continue;
        }

        // æ˜¾ç¤ºå¸®åŠ©
        if user_input == "help" {
            println!("ğŸ’¡ å¯ç”¨å‘½ä»¤:");
            println!("  toggle - åˆ‡æ¢æµå¼/å¸¸è§„æ¨¡å¼");
            println!("  help   - æ˜¾ç¤ºå¸®åŠ©");
            println!("  bye    - é€€å‡º");
            continue;
        }

        if user_input.is_empty() {
            continue;
        }

        // å¤„ç†èŠå¤©æ¶ˆæ¯
        let start_time = std::time::Instant::now();

        // ä½¿ç”¨ç®€å•çš„å­—ç¬¦ä¸²è¾“å…¥ï¼ˆå•æ¬¡å¯¹è¯ï¼Œä¸ä¿æŒå†å²ï¼‰
        store.set("input".to_string(), json!(user_input))?;

        // é€‰æ‹©èŠ‚ç‚¹
        let node = if use_streaming {
            &mut streaming_node
        } else {
            &mut regular_node
        };

        print!("ğŸ¤– AI: ");
        io::stdout().flush()?;

        if use_streaming {
            println!("(æµå¼å“åº”...)");
        }

        // æ‰§è¡ŒAPIè°ƒç”¨
        match node.prep(&store, &execution_context).await {
            Ok(messages) => {
                match <ApiRequestNode as NodeBackend<InMemoryStorage>>::exec(
                    node,
                    messages,
                    &execution_context,
                )
                .await
                {
                    Ok(response) => {
                        let duration = start_time.elapsed();

                        if use_streaming {
                            println!("{}", response);
                        } else {
                            println!("\rğŸ¤– AI: {}", response);
                        }

                        println!("â±ï¸ ç”¨æ—¶: {:.1?}", duration);
                    }
                    Err(e) => {
                        println!("âŒ é”™è¯¯: {}", e);
                        if e.to_string().contains("demo_key") {
                            println!("ğŸ’¡ è¯·è®¾ç½®çœŸå®çš„APIå¯†é’¥: export OPENAI_API_KEY=your_key");
                        }
                    }
                }
            }
            Err(e) => {
                println!("âŒ å‡†å¤‡å¤±è´¥: {}", e);
            }
        }
    }

    Ok(())
}

/// æ¼”ç¤ºä¸åŒè¾“å…¥æ ¼å¼çš„å¤„ç†
#[allow(dead_code)]
async fn demo_input_formats() -> Result<(), Box<dyn std::error::Error>> {
    println!("ğŸ“ æ¼”ç¤ºä¸åŒè¾“å…¥æ ¼å¼");

    let mut store: SharedStore<InMemoryStorage> = SharedStore::new();
    let execution_context = ExecutionContext::new(3, Duration::from_secs(10));

    let config = ApiConfig::default()
        .with_model("gpt-3.5-turbo".to_string())
        .with_stream(true);

    let mut node =
        ApiRequestNode::new("input", "output", Action::simple("next")).with_config(config);

    // 1. ç®€å•å­—ç¬¦ä¸²è¾“å…¥
    println!("\n1ï¸âƒ£ ç®€å•å­—ç¬¦ä¸²è¾“å…¥:");
    store.set("input".to_string(), json!("ä½ å¥½"))?;
    demo_api_call(&mut node, &store, &execution_context).await;

    // 2. æ¶ˆæ¯æ•°ç»„è¾“å…¥
    println!("\n2ï¸âƒ£ æ¶ˆæ¯æ•°ç»„è¾“å…¥:");
    store.set(
        "input".to_string(),
        json!([
            {"role": "user", "content": "ä»€ä¹ˆæ˜¯AIï¼Ÿ"}
        ]),
    )?;
    demo_api_call(&mut node, &store, &execution_context).await;

    // 3. å¸¦å†å²çš„å¯¹è¯
    println!("\n3ï¸âƒ£ å¸¦å†å²çš„å¯¹è¯:");
    store.set(
        "input".to_string(),
        json!([
            {"role": "user", "content": "æˆ‘æƒ³å­¦ç¼–ç¨‹"},
            {"role": "assistant", "content": "ç¼–ç¨‹æ˜¯ä¸€é¡¹å¾ˆæœ‰ç”¨çš„æŠ€èƒ½ï¼ä½ æƒ³å­¦ä»€ä¹ˆè¯­è¨€ï¼Ÿ"},
            {"role": "user", "content": "æ¨èä¸€ä¸ªé€‚åˆåˆå­¦è€…çš„è¯­è¨€"}
        ]),
    )?;
    demo_api_call(&mut node, &store, &execution_context).await;

    Ok(())
}

async fn demo_api_call(
    node: &mut ApiRequestNode,
    store: &SharedStore<InMemoryStorage>,
    context: &ExecutionContext,
) {
    match node.prep(store, context).await {
        Ok(messages) => {
            println!("âœ… å‡†å¤‡äº† {} æ¡æ¶ˆæ¯", messages.len());
            for (i, msg) in messages.iter().enumerate() {
                println!("   æ¶ˆæ¯ {}: {:?}", i + 1, msg);
            }
        }
        Err(e) => println!("âŒ å‡†å¤‡å¤±è´¥: {}", e),
    }
}
